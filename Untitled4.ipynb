{
 "metadata": {
  "name": "",
  "signature": "sha256:7f5c40beddf5531af7e38f3186aa6ee3ef3e1d81df92138cb191bafeda96b83a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Constraints performed by restricting the 1024 layer to a 32 by 32 grid, and then penalising the difference between a cell and the activations of the surrounding cells,\n",
      "\n",
      "$$\\sqrt{\\sum_{(i,j) \\in H^2,\\text{adjacent}(i,j)} (x_i - x_j)^2}$$\n",
      "\n",
      "Where $H$ are the indeces of the cells in the chosen hidden layer."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let a gaussian function parameterised by $B$ and $\\mu$ be written as,\n",
      "\n",
      "$$g(\\mathbf{c};\\mathbf{B},\\mu) = \\exp\\left(\\left\\|\n",
      "\\mathbf{B}(\\mathbf{c} - \\mu)\n",
      "\\right\\|^2\\right)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For adaptation, we say each cell lies somewhere on a 32 by 32 grid, and we want to move these around so that we rearrange the contributions for that layer to the next. We do this by pooling all activation scores within a output neuron's region, which is defined by the gaussian function.\n",
      "\n",
      "Formula is given by,\n",
      "\n",
      "$$\\hat{\\mathbf{x}}_i = \\sum_j g(\\mathbf{c}_j - \\mu_i) \\mathbf{x}_i$$\n",
      "\n",
      "And we need to adapt $\\mathbf{c}$ which is a 1024x2 matrix."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}